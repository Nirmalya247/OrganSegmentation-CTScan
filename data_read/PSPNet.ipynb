{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PSPNet.ipynb","provenance":[],"mount_file_id":"1qSZKNN4Y-AP0z9ml0QpZ_G1vEepKgFb2","authorship_tag":"ABX9TyNCOQ6m9eRwBTlbwS9zWN5H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":54,"metadata":{"id":"W48JqUdyfsIR","executionInfo":{"status":"ok","timestamp":1661499338611,"user_tz":-330,"elapsed":3,"user":{"displayName":"Nirmalya Gayen","userId":"11188689434238125777"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","DEFAULT_PADDING = 'VALID'\n","DEFAULT_DATAFORMAT = 'NHWC'\n","\n","BN_param_map = {'scale':    'gamma',\n","                'offset':   'beta',\n","                'variance': 'moving_variance',\n","                'mean':     'moving_mean'}\n","\n","def layer(op):\n","    '''Decorator for composable network layers.'''\n","\n","    def layer_decorated(self, *args, **kwargs):\n","        # Automatically set a name if not provided.\n","        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n","        # Figure out the layer inputs.\n","        if len(self.terminals) == 0:\n","            raise RuntimeError('No input variables found for layer %s.' % name)\n","        elif len(self.terminals) == 1:\n","            layer_input = self.terminals[0]\n","        else:\n","            layer_input = list(self.terminals)\n","        # Perform the operation and get the output.\n","        layer_output = op(self, layer_input, *args, **kwargs)\n","        # Add to layer LUT.\n","        self.layers[name] = layer_output\n","        # This output is now the input for the next layer.\n","        self.feed(layer_output)\n","        # Return self for chained calls.\n","        return self\n","\n","    return layer_decorated\n","\n","\n","class Network(object):\n","\n","    def __init__(self, inputs, trainable=True, is_training=False, num_classes=21):\n","        # The input nodes for this network\n","        self.inputs = inputs\n","        # The current list of terminal nodes\n","        self.terminals = []\n","        # Mapping from layer names to layers\n","        self.layers = dict(inputs)\n","        # If true, the resulting variables are set as trainable\n","        self.trainable = trainable\n","        # Switch variable for dropout\n","        self.use_dropout = tf.compat.v1.placeholder_with_default(tf.constant(1.0),\n","                                                       shape=[],\n","                                                       name='use_dropout')\n","        self.is_training = is_training\n","        self.setup(is_training, num_classes)\n","\n","    def setup(self, is_training):\n","        '''Construct the network. '''\n","        raise NotImplementedError('Must be implemented by the subclass.')\n","\n","    def load(self, data_path, session, ignore_missing=False):\n","        '''Load network weights.\n","        data_path: The path to the numpy-serialized network weights\n","        session: The current TensorFlow session\n","        ignore_missing: If true, serialized weights for missing layers are ignored.\n","        '''\n","        data_dict = np.load(data_path, encoding='latin1').item()\n","\n","        for op_name in data_dict:\n","            with tf.compat.v1.variable_scope(op_name, reuse=True):\n","                for param_name, data in data_dict[op_name].items():\n","                    try:\n","                        if 'bn' in op_name:\n","                            param_name = BN_param_map[param_name]\n","                            data = np.squeeze(data)\n","\n","                        var = tf.compat.v1.get_variable(param_name)\n","                        session.run(var.assign(data))\n","                    except ValueError:\n","                        if not ignore_missing:\n","                            raise\n","\n","    def feed(self, *args):\n","        '''Set the input(s) for the next operation by replacing the terminal nodes.\n","        The arguments can be either layer names or the actual layers.\n","        '''\n","        assert len(args) != 0\n","        self.terminals = []\n","        for fed_layer in args:\n","            if isinstance(fed_layer, str):\n","                try:\n","                    fed_layer = self.layers[fed_layer]\n","                except KeyError:\n","                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n","            self.terminals.append(fed_layer)\n","        return self\n","\n","    def get_output(self):\n","        '''Returns the current network output.'''\n","        return self.terminals[-1]\n","\n","    def get_unique_name(self, prefix):\n","        '''Returns an index-suffixed unique name for the given prefix.\n","        This is used for auto-generating layer names based on the type-prefix.\n","        '''\n","        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n","        return '%s_%d' % (prefix, ident)\n","\n","    def make_var(self, name, shape):\n","        '''Creates a new TensorFlow variable.'''\n","        return tf.compat.v1.get_variable(name, shape, trainable=self.trainable)\n","\n","    def get_layer_name(self):\n","        return layer_name\n","    def validate_padding(self, padding):\n","        '''Verifies that the padding is one of the supported ones.'''\n","        assert padding in ('SAME', 'VALID')\n","    @layer\n","    def zero_padding(self, input, paddings, name):\n","        pad_mat = np.array([[0,0], [paddings, paddings], [paddings, paddings], [0, 0]])\n","        return tf.pad(input, paddings=pad_mat, name=name)\n","\n","    @layer\n","    def conv(self,\n","             input,\n","             k_h,\n","             k_w,\n","             c_o,\n","             s_h,\n","             s_w,\n","             name,\n","             relu=True,\n","             padding=DEFAULT_PADDING,\n","             group=1,\n","             biased=True):\n","        # Verify that the padding is acceptable\n","        self.validate_padding(padding)\n","        # Get the number of channels in the input\n","        c_i = input.get_shape()[-1]\n","\n","        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding,data_format=DEFAULT_DATAFORMAT)\n","        with tf.compat.v1.variable_scope(name) as scope:\n","            kernel = self.make_var('weights', shape=[k_h, k_w, c_i, c_o])\n","            output = convolve(input, kernel)\n","\n","            if biased:\n","                biases = self.make_var('biases', [c_o])\n","                output = tf.nn.bias_add(output, biases)\n","            if relu:\n","                output = tf.nn.relu(output, name=scope.name)\n","            return output\n","\n","    @layer\n","    def atrous_conv(self,\n","                    input,\n","                    k_h,\n","                    k_w,\n","                    c_o,\n","                    dilation,\n","                    name,\n","                    relu=True,\n","                    padding=DEFAULT_PADDING,\n","                    group=1,\n","                    biased=True):\n","        # Verify that the padding is acceptable\n","        self.validate_padding(padding)\n","        # Get the number of channels in the input\n","        c_i = input.get_shape()[-1]\n","\n","        convolve = lambda i, k: tf.nn.atrous_conv2d(i, k, dilation, padding=padding)\n","        with tf.compat.v1.variable_scope(name) as scope:\n","            kernel = self.make_var('weights', shape=[k_h, k_w, c_i, c_o])\n","            output = convolve(input, kernel)\n","\n","            if biased:\n","                biases = self.make_var('biases', [c_o])\n","                output = tf.nn.bias_add(output, biases)\n","            if relu:\n","                output = tf.nn.relu(output, name=scope.name)\n","            return output\n","\n","    @layer\n","    def relu(self, input, name):\n","        return tf.nn.relu(input, name=name)\n","\n","    @layer\n","    def max_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n","        self.validate_padding(padding)\n","        return tf.nn.max_pool(input,\n","                              ksize=[1, k_h, k_w, 1],\n","                              strides=[1, s_h, s_w, 1],\n","                              padding=padding,\n","                              name=name,\n","                              data_format=DEFAULT_DATAFORMAT)\n","\n","    @layer\n","    def avg_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n","        self.validate_padding(padding)\n","        output = tf.nn.avg_pool(input,\n","                              ksize=[1, k_h, k_w, 1],\n","                              strides=[1, s_h, s_w, 1],\n","                              padding=padding,\n","                              name=name,\n","                              data_format=DEFAULT_DATAFORMAT)\n","        return output\n","\n","    @layer\n","    def lrn(self, input, radius, alpha, beta, name, bias=1.0):\n","        return tf.nn.local_response_normalization(input,\n","                                                  depth_radius=radius,\n","                                                  alpha=alpha,\n","                                                  beta=beta,\n","                                                  bias=bias,\n","                                                  name=name)\n","\n","    @layer\n","    def concat(self, inputs, axis, name):\n","        return tf.concat(axis=axis, values=inputs, name=name)\n","\n","    @layer\n","    def add(self, inputs, name):\n","        return tf.add_n(inputs, name=name)\n","\n","    @layer\n","    def fc(self, input, num_out, name, relu=True):\n","        with tf.compat.v1.variable_scope(name) as scope:\n","            input_shape = input.get_shape()\n","            if input_shape.ndims == 4:\n","                # The input is spatial. Vectorize it first.\n","                dim = 1\n","                for d in input_shape[1:].as_list():\n","                    dim *= d\n","                feed_in = tf.reshape(input, [-1, dim])\n","            else:\n","                feed_in, dim = (input, input_shape[-1].value)\n","            weights = self.make_var('weights', shape=[dim, num_out])\n","            biases = self.make_var('biases', [num_out])\n","            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n","            fc = op(feed_in, weights, biases, name=scope.name)\n","            return fc\n","\n","    @layer\n","    def softmax(self, input, name):\n","        input_shape = map(lambda v: v.value, input.get_shape())\n","        if len(input_shape) > 2:\n","            # For certain models (like NiN), the singleton spatial dimensions\n","            # need to be explicitly squeezed, since they're not broadcast-able\n","            # in TensorFlow's NHWC ordering (unlike Caffe's NCHW).\n","            if input_shape[1] == 1 and input_shape[2] == 1:\n","                input = tf.squeeze(input, squeeze_dims=[1, 2])\n","            else:        return tf.nn.softmax(input, name)\n","\n","    @layer\n","    def batch_normalization(self, input, name, scale_offset=True, relu=False):\n","        output = tf.layers.batch_normalization(\n","            input,\n","            momentum=0.95,\n","            epsilon=1e-5,\n","            training=self.is_training,\n","            name=name\n","        )\n","\n","        if relu:\n","            output = tf.nn.relu(output)\n","\n","        return output\n","\n","    @layer\n","    def dropout(self, input, keep_prob, name):\n","        keep = 1 - self.use_dropout + (self.use_dropout * keep_prob)\n","        return tf.nn.dropout(input, keep, name=name)\n","\n","    @layer\n","    def resize_bilinear(self, input, size, name):\n","        return tf.image.resize_bilinear(input, size=size, align_corners=True, name=name)"]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","class PSPNet101(Network):\n","    def setup(self, is_training, num_classes):\n","        '''Network definition.\n","        Args:\n","          is_training: whether to update the running mean and variance of the batch normalisation layer.\n","                       If the batch size is small, it is better to keep the running mean and variance of\n","                       the-pretrained model frozen.\n","          num_classes: number of classes to predict (including background).\n","        '''\n","        (self.feed('data')\n","             .conv(3, 3, 64, 2, 2, biased=False, relu=False, padding='SAME', name='conv1_1_3x3_s2')\n","             .batch_normalization(relu=False, name='conv1_1_3x3_s2_bn')\n","             .relu(name='conv1_1_3x3_s2_bn_relu')\n","             .conv(3, 3, 64, 1, 1, biased=False, relu=False, padding='SAME', name='conv1_2_3x3')\n","             .batch_normalization(relu=True, name='conv1_2_3x3_bn')\n","             .conv(3, 3, 128, 1, 1, biased=False, relu=False, padding='SAME', name='conv1_3_3x3')\n","             .batch_normalization(relu=True, name='conv1_3_3x3_bn')\n","             .max_pool(3, 3, 2, 2, padding='SAME', name='pool1_3x3_s2')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv2_1_1x1_proj')\n","             .batch_normalization(relu=False, name='conv2_1_1x1_proj_bn'))\n","\n","        (self.feed('pool1_3x3_s2')\n","             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='conv2_1_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv2_1_1x1_reduce_bn')\n","             .zero_padding(paddings=1, name='padding1')\n","             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='conv2_1_3x3')\n","             .batch_normalization(relu=True, name='conv2_1_3x3_bn')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv2_1_1x1_increase')\n","             .batch_normalization(relu=False, name='conv2_1_1x1_increase_bn'))\n","\n","        (self.feed('conv2_1_1x1_proj_bn',\n","                   'conv2_1_1x1_increase_bn')\n","             .add(name='conv2_1')\n","             .relu(name='conv2_1/relu')\n","             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='conv2_2_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv2_2_1x1_reduce_bn')\n","             .zero_padding(paddings=1, name='padding2')\n","             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='conv2_2_3x3')\n","             .batch_normalization(relu=True, name='conv2_2_3x3_bn')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv2_2_1x1_increase')\n","             .batch_normalization(relu=False, name='conv2_2_1x1_increase_bn'))\n","\n","        (self.feed('conv2_1/relu',\n","                   'conv2_2_1x1_increase_bn')\n","             .add(name='conv2_2')\n","             .relu(name='conv2_2/relu')\n","             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='conv2_3_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv2_3_1x1_reduce_bn')\n","             .zero_padding(paddings=1, name='padding3')\n","             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='conv2_3_3x3')\n","             .batch_normalization(relu=True, name='conv2_3_3x3_bn')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv2_3_1x1_increase')\n","             .batch_normalization(relu=False, name='conv2_3_1x1_increase_bn'))\n","\n","        (self.feed('conv2_2/relu',\n","                   'conv2_3_1x1_increase_bn')\n","             .add(name='conv2_3')\n","             .relu(name='conv2_3/relu')\n","             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='conv3_1_1x1_proj')\n","             .batch_normalization(relu=False, name='conv3_1_1x1_proj_bn'))\n","\n","        (self.feed('conv2_3/relu')\n","             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='conv3_1_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv3_1_1x1_reduce_bn')\n","             .zero_padding(paddings=1, name='padding4')\n","             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='conv3_1_3x3')\n","             .batch_normalization(relu=True, name='conv3_1_3x3_bn')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv3_1_1x1_increase')\n","             .batch_normalization(relu=False, name='conv3_1_1x1_increase_bn'))\n","\n","        (self.feed('conv3_1_1x1_proj_bn',\n","                   'conv3_1_1x1_increase_bn')\n","             .add(name='conv3_1')\n","             .relu(name='conv3_1/relu')\n","             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='conv3_2_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv3_2_1x1_reduce_bn')\n","             .zero_padding(paddings=1, name='padding5')\n","             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='conv3_2_3x3')\n","             .batch_normalization(relu=True, name='conv3_2_3x3_bn')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv3_2_1x1_increase')\n","             .batch_normalization(relu=False, name='conv3_2_1x1_increase_bn'))\n","\n","        (self.feed('conv3_1/relu',\n","                   'conv3_2_1x1_increase_bn')\n","             .add(name='conv3_2')\n","             .relu(name='conv3_2/relu')\n","             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='conv3_3_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv3_3_1x1_reduce_bn')\n","             .zero_padding(paddings=1, name='padding6')\n","             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='conv3_3_3x3')\n","             .batch_normalization(relu=True, name='conv3_3_3x3_bn')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv3_3_1x1_increase')\n","             .batch_normalization(relu=False, name='conv3_3_1x1_increase_bn'))\n","\n","        (self.feed('conv3_2/relu',\n","                   'conv3_3_1x1_increase_bn')\n","             .add(name='conv3_3')\n","             .relu(name='conv3_3/relu')\n","             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='conv3_4_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv3_4_1x1_reduce_bn')\n","             .zero_padding(paddings=1, name='padding7')\n","             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='conv3_4_3x3')\n","             .batch_normalization(relu=True, name='conv3_4_3x3_bn')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv3_4_1x1_increase')\n","             .batch_normalization(relu=False, name='conv3_4_1x1_increase_bn'))\n","\n","        (self.feed('conv3_3/relu',\n","                   'conv3_4_1x1_increase_bn')\n","             .add(name='conv3_4')\n","             .relu(name='conv3_4/relu')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_1_1x1_proj')\n","             .batch_normalization(relu=False, name='conv4_1_1x1_proj_bn'))\n","\n","        (self.feed('conv3_4/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_1_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_1_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding8')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_1_3x3')\n","             .batch_normalization(relu=True, name='conv4_1_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_1_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_1_1x1_increase_bn'))\n","\n","        (self.feed('conv4_1_1x1_proj_bn',\n","                   'conv4_1_1x1_increase_bn')\n","             .add(name='conv4_1')\n","             .relu(name='conv4_1/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_2_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_2_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding9')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_2_3x3')\n","             .batch_normalization(relu=True, name='conv4_2_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_2_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_2_1x1_increase_bn'))\n","\n","        (self.feed('conv4_1/relu',\n","                   'conv4_2_1x1_increase_bn')\n","             .add(name='conv4_2')\n","             .relu(name='conv4_2/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_3_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_3_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding10')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_3_3x3')\n","             .batch_normalization(relu=True, name='conv4_3_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_3_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_3_1x1_increase_bn'))\n","\n","        (self.feed('conv4_2/relu',\n","                   'conv4_3_1x1_increase_bn')\n","             .add(name='conv4_3')\n","             .relu(name='conv4_3/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_4_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_4_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding11')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_4_3x3')\n","             .batch_normalization(relu=True, name='conv4_4_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_4_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_4_1x1_increase_bn'))\n","\n","        (self.feed('conv4_3/relu',\n","                   'conv4_4_1x1_increase_bn')\n","             .add(name='conv4_4')\n","             .relu(name='conv4_4/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_5_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_5_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding12')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_5_3x3')\n","             .batch_normalization(relu=True, name='conv4_5_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_5_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_5_1x1_increase_bn'))\n","\n","        (self.feed('conv4_4/relu',\n","                   'conv4_5_1x1_increase_bn')\n","             .add(name='conv4_5')\n","             .relu(name='conv4_5/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_6_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_6_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding13')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_6_3x3')\n","             .batch_normalization(relu=True, name='conv4_6_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_6_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_6_1x1_increase_bn'))\n","\n","        (self.feed('conv4_5/relu',\n","                   'conv4_6_1x1_increase_bn')\n","             .add(name='conv4_6')\n","             .relu(name='conv4_6/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_7_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_7_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding14')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_7_3x3')\n","             .batch_normalization(relu=True, name='conv4_7_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_7_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_7_1x1_increase_bn'))\n","\n","        (self.feed('conv4_6/relu',\n","                   'conv4_7_1x1_increase_bn')\n","             .add(name='conv4_7')\n","             .relu(name='conv4_7/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_8_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_8_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding15')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_8_3x3')\n","             .batch_normalization(relu=True, name='conv4_8_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_8_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_8_1x1_increase_bn'))\n","\n","        (self.feed('conv4_7/relu',\n","                   'conv4_8_1x1_increase_bn')\n","             .add(name='conv4_8')\n","             .relu(name='conv4_8/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_9_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_9_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding16')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_9_3x3')\n","             .batch_normalization(relu=True, name='conv4_9_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_9_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_9_1x1_increase_bn'))\n","\n","        (self.feed('conv4_8/relu',\n","                   'conv4_9_1x1_increase_bn')\n","             .add(name='conv4_9')\n","             .relu(name='conv4_9/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_10_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_10_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding17')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_10_3x3')\n","             .batch_normalization(relu=True, name='conv4_10_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_10_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_10_1x1_increase_bn'))\n","\n","        (self.feed('conv4_9/relu',\n","                   'conv4_10_1x1_increase_bn')\n","             .add(name='conv4_10')\n","             .relu(name='conv4_10/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_11_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_11_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding18')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_11_3x3')\n","             .batch_normalization(relu=True, name='conv4_11_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_11_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_11_1x1_increase_bn'))\n","\n","        (self.feed('conv4_10/relu',\n","                   'conv4_11_1x1_increase_bn')\n","             .add(name='conv4_11')\n","             .relu(name='conv4_11/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_12_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_12_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding19')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_12_3x3')\n","             .batch_normalization(relu=True, name='conv4_12_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_12_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_12_1x1_increase_bn'))\n","\n","        (self.feed('conv4_11/relu',\n","                   'conv4_12_1x1_increase_bn')\n","             .add(name='conv4_12')\n","             .relu(name='conv4_12/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_13_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_13_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding20')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_13_3x3')\n","             .batch_normalization(relu=True, name='conv4_13_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_13_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_13_1x1_increase_bn'))\n","\n","        (self.feed('conv4_12/relu',\n","                   'conv4_13_1x1_increase_bn')\n","             .add(name='conv4_13')\n","             .relu(name='conv4_13/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_14_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_14_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding21')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_14_3x3')\n","             .batch_normalization(relu=True, name='conv4_14_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_14_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_14_1x1_increase_bn'))\n","\n","        (self.feed('conv4_13/relu',\n","                   'conv4_14_1x1_increase_bn')\n","             .add(name='conv4_14')\n","             .relu(name='conv4_14/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_15_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_15_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding22')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_15_3x3')\n","             .batch_normalization(relu=True, name='conv4_15_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_15_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_15_1x1_increase_bn'))\n","\n","        (self.feed('conv4_14/relu',\n","                   'conv4_15_1x1_increase_bn')\n","             .add(name='conv4_15')\n","             .relu(name='conv4_15/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_16_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_16_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding23')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_16_3x3')\n","             .batch_normalization(relu=True, name='conv4_16_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_16_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_16_1x1_increase_bn'))\n","\n","        (self.feed('conv4_15/relu',\n","                   'conv4_16_1x1_increase_bn')\n","             .add(name='conv4_16')\n","             .relu(name='conv4_16/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_17_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_17_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding24')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_17_3x3')\n","             .batch_normalization(relu=True, name='conv4_17_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_17_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_17_1x1_increase_bn'))\n","\n","        (self.feed('conv4_16/relu',\n","                   'conv4_17_1x1_increase_bn')\n","             .add(name='conv4_17')\n","             .relu(name='conv4_17/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_18_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_18_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding25')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_18_3x3')\n","             .batch_normalization(relu=True, name='conv4_18_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_18_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_18_1x1_increase_bn'))\n","\n","        (self.feed('conv4_17/relu',\n","                   'conv4_18_1x1_increase_bn')\n","             .add(name='conv4_18')\n","             .relu(name='conv4_18/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_19_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_19_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding26')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_19_3x3')\n","             .batch_normalization(relu=True, name='conv4_19_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_19_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_19_1x1_increase_bn'))\n","\n","        (self.feed('conv4_18/relu',\n","                   'conv4_19_1x1_increase_bn')\n","             .add(name='conv4_19')\n","             .relu(name='conv4_19/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_20_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_20_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding27')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_20_3x3')\n","             .batch_normalization(relu=True, name='conv4_20_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_20_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_20_1x1_increase_bn'))\n","\n","        (self.feed('conv4_19/relu',\n","                   'conv4_20_1x1_increase_bn')\n","             .add(name='conv4_20')\n","             .relu(name='conv4_20/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_21_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_21_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding28')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_21_3x3')\n","             .batch_normalization(relu=True, name='conv4_21_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_21_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_21_1x1_increase_bn'))\n","\n","        (self.feed('conv4_20/relu',\n","                   'conv4_21_1x1_increase_bn')\n","             .add(name='conv4_21')\n","             .relu(name='conv4_21/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_22_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_22_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding29')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_22_3x3')\n","             .batch_normalization(relu=True, name='conv4_22_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_22_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_22_1x1_increase_bn'))\n","\n","        (self.feed('conv4_21/relu',\n","                   'conv4_22_1x1_increase_bn')\n","             .add(name='conv4_22')\n","             .relu(name='conv4_22/relu')\n","             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='conv4_23_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv4_23_1x1_reduce_bn')\n","             .zero_padding(paddings=2, name='padding30')\n","             .atrous_conv(3, 3, 256, 2, biased=False, relu=False, name='conv4_23_3x3')\n","             .batch_normalization(relu=True, name='conv4_23_3x3_bn')\n","             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='conv4_23_1x1_increase')\n","             .batch_normalization(relu=False, name='conv4_23_1x1_increase_bn'))\n","\n","        (self.feed('conv4_22/relu',\n","                   'conv4_23_1x1_increase_bn')\n","             .add(name='conv4_23')\n","             .relu(name='conv4_23/relu')\n","             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='conv5_1_1x1_proj')\n","             .batch_normalization(relu=False, name='conv5_1_1x1_proj_bn'))\n","\n","        (self.feed('conv4_23/relu')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv5_1_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv5_1_1x1_reduce_bn')\n","             .zero_padding(paddings=4, name='padding31')\n","             .atrous_conv(3, 3, 512, 4, biased=False, relu=False, name='conv5_1_3x3')\n","             .batch_normalization(relu=True, name='conv5_1_3x3_bn')\n","             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='conv5_1_1x1_increase')\n","             .batch_normalization(relu=False, name='conv5_1_1x1_increase_bn'))\n","\n","        (self.feed('conv5_1_1x1_proj_bn',\n","                   'conv5_1_1x1_increase_bn')\n","             .add(name='conv5_1')\n","             .relu(name='conv5_1/relu')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv5_2_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv5_2_1x1_reduce_bn')\n","             .zero_padding(paddings=4, name='padding32')\n","             .atrous_conv(3, 3, 512, 4, biased=False, relu=False, name='conv5_2_3x3')\n","             .batch_normalization(relu=True, name='conv5_2_3x3_bn')\n","             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='conv5_2_1x1_increase')\n","             .batch_normalization(relu=False, name='conv5_2_1x1_increase_bn'))\n","\n","        (self.feed('conv5_1/relu',\n","                   'conv5_2_1x1_increase_bn')\n","             .add(name='conv5_2')\n","             .relu(name='conv5_2/relu')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv5_3_1x1_reduce')\n","             .batch_normalization(relu=True, name='conv5_3_1x1_reduce_bn')\n","             .zero_padding(paddings=4, name='padding33')\n","             .atrous_conv(3, 3, 512, 4, biased=False, relu=False, name='conv5_3_3x3')\n","             .batch_normalization(relu=True, name='conv5_3_3x3_bn')\n","             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='conv5_3_1x1_increase')\n","             .batch_normalization(relu=False, name='conv5_3_1x1_increase_bn'))\n","\n","        (self.feed('conv5_2/relu',\n","                   'conv5_3_1x1_increase_bn')\n","             .add(name='conv5_3')\n","             .relu(name='conv5_3/relu'))\n","\n","        conv5_3 = self.layers['conv5_3/relu']\n","        shape = tf.shape(conv5_3)[1:3]\n","\n","        (self.feed('conv5_3/relu')\n","             .avg_pool(90, 90, 90, 90, name='conv5_3_pool1')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv5_3_pool1_conv')\n","             .batch_normalization(relu=True, name='conv5_3_pool1_conv_bn')\n","             .resize_bilinear(shape, name='conv5_3_pool1_interp'))\n","\n","        (self.feed('conv5_3/relu')\n","             .avg_pool(45, 45, 45, 45, name='conv5_3_pool2')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv5_3_pool2_conv')\n","             .batch_normalization(relu=True, name='conv5_3_pool2_conv_bn')\n","             .resize_bilinear(shape, name='conv5_3_pool2_interp'))\n","\n","        (self.feed('conv5_3/relu')\n","             .avg_pool(30, 30, 30, 30, name='conv5_3_pool3')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv5_3_pool3_conv')\n","             .batch_normalization(relu=True, name='conv5_3_pool3_conv_bn')\n","             .resize_bilinear(shape, name='conv5_3_pool3_interp'))\n","\n","        (self.feed('conv5_3/relu')\n","             .avg_pool(15, 15, 15, 15, name='conv5_3_pool6')\n","             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='conv5_3_pool6_conv')\n","             .batch_normalization(relu=True, name='conv5_3_pool6_conv_bn')\n","             .resize_bilinear(shape, name='conv5_3_pool6_interp'))\n","\n","        (self.feed('conv5_3/relu',\n","                   'conv5_3_pool6_interp',\n","                   'conv5_3_pool3_interp',\n","                   'conv5_3_pool2_interp',\n","                   'conv5_3_pool1_interp')\n","             .concat(axis=-1, name='conv5_3_concat')\n","             .conv(3, 3, 512, 1, 1, biased=False, relu=False, padding='SAME', name='conv5_4')\n","             .batch_normalization(relu=True, name='conv5_4_bn')\n","             .conv(1, 1, num_classes, 1, 1, biased=True, relu=False, name='conv6'))"],"metadata":{"id":"zwjDw7I4hpZo","executionInfo":{"status":"ok","timestamp":1661499340026,"user_tz":-330,"elapsed":5,"user":{"displayName":"Nirmalya Gayen","userId":"11188689434238125777"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["imagex = np.load(\"/content/drive/MyDrive/ColabNotebooks/project/nifti/0_range/organ1/x-real-1-100-128x128x1-skip0.npy\")"],"metadata":{"id":"ph9vroTU3G-q","executionInfo":{"status":"ok","timestamp":1661496580320,"user_tz":-330,"elapsed":1088,"user":{"displayName":"Nirmalya Gayen","userId":"11188689434238125777"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["imagey = np.load(\"/content/drive/MyDrive/ColabNotebooks/project/nifti/0_range/organ1/y-border-1-100-128x128x2-skip0.npy\")"],"metadata":{"id":"vzBGGokv6Orx","executionInfo":{"status":"ok","timestamp":1661496585950,"user_tz":-330,"elapsed":5632,"user":{"displayName":"Nirmalya Gayen","userId":"11188689434238125777"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["image_batch, label_batch = tf.train.batch([imagex, imagey], 1000)"],"metadata":{"id":"OEGKTWEP6MUB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_batch2 = tf.dtypes.cast(image_batch, tf.double)"],"metadata":{"id":"zEFbQNyo4jXY","executionInfo":{"status":"ok","timestamp":1661497924961,"user_tz":-330,"elapsed":590,"user":{"displayName":"Nirmalya Gayen","userId":"11188689434238125777"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["image_batch2.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xWyMFKs9dIT","executionInfo":{"status":"ok","timestamp":1661498070882,"user_tz":-330,"elapsed":509,"user":{"displayName":"Nirmalya Gayen","userId":"11188689434238125777"}},"outputId":"a537fb3f-8a8d-4d6b-b9b6-d88655cd91a7"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tf.float64"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["image_batch.get_shape()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lAk0TWxb4sFT","executionInfo":{"status":"ok","timestamp":1661496126525,"user_tz":-330,"elapsed":4,"user":{"displayName":"Nirmalya Gayen","userId":"11188689434238125777"}},"outputId":"01ad2889-59b7-45b4-c649-63b8d785f4d9"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([3859, 128, 128, 1])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["type(imagey[0][0][0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V5Nm1paJ8iEM","executionInfo":{"status":"ok","timestamp":1661498257537,"user_tz":-330,"elapsed":556,"user":{"displayName":"Nirmalya Gayen","userId":"11188689434238125777"}},"outputId":"13274983-d90d-4d7e-8f3c-1a65309d98ad"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.int64"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["net = PSPNet101({'data': image_batch2}, is_training=True, num_classes=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"SGrIsMSJizsj","executionInfo":{"status":"error","timestamp":1661499344421,"user_tz":-330,"elapsed":737,"user":{"displayName":"Nirmalya Gayen","userId":"11188689434238125777"}},"outputId":"a61589f8-d0a4-490e-d263-96b2d0d8ab0e"},"execution_count":56,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-2357ba32c8c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPSPNet101\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_batch2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-54-228e0ba4facb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, trainable, is_training, num_classes)\u001b[0m\n\u001b[1;32m     51\u001b[0m                                                        name='use_dropout')\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-55-c332d5fd78e7>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, is_training, num_classes)\u001b[0m\n\u001b[1;32m     11\u001b[0m         '''\n\u001b[1;32m     12\u001b[0m         (self.feed('data')\n\u001b[0;32m---> 13\u001b[0;31m              \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1_1_3x3_s2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1_1_3x3_s2_bn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1_1_3x3_s2_bn_relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-54-228e0ba4facb>\u001b[0m in \u001b[0;36mlayer_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mlayer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Perform the operation and get the output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Add to layer LUT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-54-228e0ba4facb>\u001b[0m in \u001b[0;36mconv\u001b[0;34m(self, input, k_h, k_w, c_o, s_h, s_w, name, relu, padding, group, biased)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_o\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbiased\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-54-228e0ba4facb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, k)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mc_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mconvolve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_DATAFORMAT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_o\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Conv2D as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Conv2D]"]}]}]}